{{- if .Values.spark.enabled }}
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ printf "%s-master" (include "spark.name" .) }}
  namespace: {{ .Release.Namespace | quote }}
  labels: 
    {{- include "spark.labels" . | nindent 4}}
    app.kubernetes.io/component: master
spec:
  selector:
    matchLabels: 
      {{- include "spark.selectorLabels" . | nindent 6}}
      app.kubernetes.io/component: master
  serviceName: {{ printf "%s-headless" (include "spark.name" .) }}
  replicas: 1
  podManagementPolicy: Parallel
  template:
    metadata:
      labels: 
        {{- include "spark.labels" . | nindent 8}}
        app.kubernetes.io/component: master
    spec:
      volumes:
        - name: spark-configmap
          configMap:
            name: spark-configmap
      terminationGracePeriodSeconds: 30
      containers:
      - name: spark-master
        image: {{ include "spark.image" . }}
        imagePullPolicy: {{ .Values.spark.image.pullPolicy | quote }}
        env:
        - name: SPARK_MODE
          value: master
        - name: SPARK_PUBLIC_DNS
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        {{- if .Values.spark.master.daemonMemoryLimit }}
        - name: SPARK_DAEMON_MEMORY
          value: {{ .Values.spark.master.daemonMemoryLimit | quote }}
        {{- end}}
        {{- if .Values.spark.master.resources }}
        resources: {{- toYaml .Values.spark.master.resources | nindent 10 }}
        {{- end}}
        volumeMounts:
          - mountPath: /opt/bitnami/spark/conf/spark-defaults.conf
            name: spark-configmap
            subPath: spark-defaults.conf
          - mountPath: /opt/bitnami/spark/conf/log4j2.properties
            name: spark-configmap
            subPath: log4j2.properties

        ports:
        - name: webui
          protocol: TCP
          containerPort: {{ .Values.spark.master.containerPorts.webui }}
          {{- if (eq .Values.spark.service.type "ClusterIP") }}
          hostPort: {{ .Values.spark.master.ports.webui }}
          {{- end }}
        - name: rpc
          protocol: TCP
          containerPort: {{ .Values.spark.master.containerPorts.rpc }}

      {{- if .Values.affinity.enabled }}
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions: [{key: 'app.kubernetes.io/name', operator: In, values: [spark]}]
            topologyKey: "kubernetes.io/hostname"
      {{- end }}

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: {{ printf "%s-worker" (include "spark.name" .) }}
  namespace: {{ .Release.Namespace | quote }}
  labels: 
    {{- include "spark.labels" . | nindent 4}}
    app.kubernetes.io/component: worker
spec:
  selector:
    matchLabels: 
      {{- include "spark.selectorLabels" . | nindent 6}}
      app.kubernetes.io/component: worker
  serviceName: {{ printf "%s-headless" (include "spark.name" .) }}
  replicas: {{ .Values.spark.worker.replicas }}
  podManagementPolicy: Parallel
  template:
    metadata:
      labels: 
        {{- include "spark.labels" . | nindent 8}}
        app.kubernetes.io/component: worker
    spec:
      volumes:
        - name: spark-configmap
          configMap:
            name: spark-configmap
      terminationGracePeriodSeconds: 30
      containers:
      - name: spark-worker
        image: {{ include "spark.image" . }}
        imagePullPolicy: {{ .Values.spark.image.pullPolicy | quote }}
        env:
        - name: SPARK_MODE
          value: "worker"
        - name: SPARK_PUBLIC_DNS
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        {{- if .Values.spark.worker.daemonMemoryLimit }}
        - name: SPARK_DAEMON_MEMORY
          value: {{ .Values.spark.worker.daemonMemoryLimit | quote }}
        {{- end }}
        {{- if .Values.spark.worker.memoryLimit }}
        - name: SPARK_WORKER_MEMORY
          value: {{ .Values.spark.worker.memoryLimit | quote }}
        {{- end }}
        - name: SPARK_MASTER_URL
          value: {{ printf "spark://%s-master-svc:%d" (include "spark.name" .) (int .Values.spark.master.ports.rpc) }}
        {{- if .Values.spark.worker.resources }}
        resources: {{- toYaml .Values.spark.worker.resources | nindent 10 }}
        {{- end}}
        volumeMounts:
          - mountPath: /opt/bitnami/spark/conf/spark-defaults.conf
            name: spark-configmap
            subPath: spark-defaults.conf
          - mountPath: /opt/bitnami/spark/conf/log4j2.properties
            name: spark-configmap
            subPath: log4j2.properties

        ports:
        - name: webui
          protocol: TCP
          containerPort: {{ .Values.spark.worker.containerPorts.webui }}
          {{- if (eq .Values.spark.service.type "ClusterIP") }}
          hostPort: {{ .Values.spark.worker.ports.webui }}
          {{- end }}
        - name: driverui
          protocol: TCP
          containerPort: {{ .Values.spark.worker.containerPorts.driverui }}
          {{- if (eq .Values.spark.service.type "ClusterIP") }}
          hostPort: {{ .Values.spark.worker.ports.driverui }}
          {{- end }}
      {{- if .Values.affinity.enabled }}
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchExpressions: [{key: 'app.kubernetes.io/name', operator: In, values: [spark]}]
            topologyKey: "kubernetes.io/hostname"
      {{- end }}            
{{- end }}
